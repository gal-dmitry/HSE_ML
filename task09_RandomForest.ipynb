{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LH5PiGz04q5-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bQUJHTjS4q5-"
   },
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    _, counts = np.unique(x, return_counts=True)\n",
    "    proba = counts / len(x)\n",
    "    return np.sum(proba * (1 - proba))\n",
    "    \n",
    "def entropy(x):\n",
    "    _, counts = np.unique(x, return_counts=True)\n",
    "    proba = counts / len(x)\n",
    "    return -np.sum(proba * np.log2(proba))\n",
    "\n",
    "def gain(left_y, right_y, criterion):\n",
    "    y = np.concatenate((left_y, right_y))\n",
    "    return criterion(y) - (criterion(left_y) * len(left_y) + criterion(right_y) * len(right_y)) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf():\n",
    "    def __init__(self, labels):\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        p = counts/np.sum(counts)\n",
    "        dct = dict(zip(unique, p))\n",
    "        self.y = max(dct)\n",
    "        self.cl = dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode():     \n",
    "    def __init__(self, split_dim, left, right):\n",
    "        self.split_dim = split_dim\n",
    "        self.split_value = 0\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, X, y,\n",
    "                 criterion=\"gini\", \n",
    "                 max_depth=None, \n",
    "                 min_samples_leaf=1,\n",
    "                 max_features=\"auto\"):\n",
    "        \n",
    "        if criterion != 'gini' and criterion != 'entropy':\n",
    "            raise ValueError('Unknown criterion')\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        self.max_features = round(np.sqrt(X.shape[1])) if max_features==\"auto\" else max_features\n",
    "                \n",
    "        indices = np.linspace(0, X.shape[0]-1, X.shape[0], dtype=int)\n",
    "        new_indices = np.random.choice(X.shape[0], X.shape[0])\n",
    "        oob_indices = np.setdiff1d(indices, new_indices)\n",
    "           \n",
    "        self.oob_X = X[oob_indices]\n",
    "        self.oob_y = y[oob_indices]\n",
    "                \n",
    "        self.root = self.build(X[new_indices], y[new_indices])\n",
    "        \n",
    "    \n",
    "    def build(self, X, y, curr_depth=0):\n",
    "        if curr_depth == self.max_depth:\n",
    "            step = DecisionTreeLeaf(y)\n",
    "    \n",
    "        else:\n",
    "            IG = 0\n",
    "            curr_dim = None\n",
    "            max_left = None\n",
    "            max_right = None\n",
    "            \n",
    "            for dim in np.random.choice(X.shape[1], self.max_features, replace=False):\n",
    "                    \n",
    "                left = np.where(X[:,dim] == 0)\n",
    "                right = np.where(X[:,dim] == 1)\n",
    "                    \n",
    "                if min(y[left].shape[0], y[right].shape[0]) < self.min_samples_leaf:\n",
    "                    continue\n",
    "                                                   \n",
    "                new_IG = gain(y[left], y[right], gini) if self.criterion=='gini' else gain(y[left], y[right], entropy)\n",
    "                    \n",
    "                if new_IG > IG: \n",
    "                    IG = new_IG\n",
    "                    curr_dim = dim\n",
    "                    max_left = left\n",
    "                    max_right = right\n",
    "                                        \n",
    "            if IG == 0:\n",
    "                step = DecisionTreeLeaf(y)\n",
    "                \n",
    "            else:\n",
    "                curr_depth += 1\n",
    "                left_node = self.build(X[max_left], y[max_left], curr_depth)\n",
    "                right_node = self.build(X[max_right], y[max_right], curr_depth)\n",
    "                step = DecisionTreeNode(curr_dim, left_node, right_node)\n",
    "            \n",
    "        return step\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):           \n",
    "        n = X.shape[0]\n",
    "        indices = np.linspace(0, n-1, n, dtype=int).reshape(n, 1)\n",
    "        \n",
    "        X_ = np.copy(X)\n",
    "        data = np.concatenate((X_, indices), axis=1)\n",
    "        curr_node = self.root\n",
    "        \n",
    "        new_array = self.func(data, curr_node)\n",
    "        sorted_array = new_array[new_array[:,0].argsort()]\n",
    "        \n",
    "        return sorted_array[:,1]\n",
    "        \n",
    "        \n",
    "    def func(self, data, curr_node):\n",
    "        \n",
    "        if isinstance(curr_node, DecisionTreeLeaf):\n",
    "            dicts = np.array([curr_node.cl for i in range(data.shape[0])])\n",
    "            indices = data[:,-1]           \n",
    "            return np.stack((indices, dicts)).T\n",
    "        \n",
    "        else:\n",
    "            left_node = curr_node.left\n",
    "            left_part = data[data[:,curr_node.split_dim] <= curr_node.split_value]\n",
    "            \n",
    "            right_node = curr_node.right\n",
    "            right_part = data[data[:,curr_node.split_dim] > curr_node.split_value]\n",
    "    \n",
    "            return np.concatenate((self.func(left_part, left_node), self.func(right_part, right_node)))\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return [max(p.keys(), key=lambda k: p[k]) for p in proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "APIy88YW4q6A"
   },
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", n_estimators=10):\n",
    "        if criterion != 'gini' and criterion != 'entropy':\n",
    "            raise ValueError('Unknown criterion')\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        self.max_features = round(np.sqrt(X.shape[1])) if max_features==\"auto\" else max_features\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "        self.features = None\n",
    "        self.forest = None\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.features = X.shape[1]\n",
    "        self.forest = [DecisionTree(X, y,\n",
    "                                  criterion=self.criterion, \n",
    "                                  max_depth=self.max_depth, \n",
    "                                  min_samples_leaf=self.min_samples_leaf, \n",
    "                                  max_features=self.max_features) for i in range(self.n_estimators)]\n",
    "\n",
    "        \n",
    "    def predict(self, X):        \n",
    "        prediction_labels = np.zeros((self.n_estimators, X.shape[0]), dtype=object)\n",
    "        \n",
    "        for i, tree in enumerate(self.forest): \n",
    "            prediction_labels[i] = tree.predict(X)\n",
    " \n",
    "        u, indices = np.unique(prediction_labels, return_inverse=True)\n",
    "        return u[np.argmax(np.apply_along_axis(np.bincount, 0, indices.reshape(prediction_labels.shape),\n",
    "                                               None, np.max(indices) + 1), axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rEmVG1Fl4q6B"
   },
   "outputs": [],
   "source": [
    "def feature_importance(rfc):\n",
    "    importance = np.zeros(rfc.features)\n",
    "    \n",
    "    for feature in range(rfc.features):\n",
    "        for tree in rfc.forest:\n",
    "        \n",
    "            y_true = tree.oob_y\n",
    "            y_pred = tree.predict(tree.oob_X) \n",
    "            acc = np.mean(y_true == y_pred)\n",
    "            err_oob = 1 - acc\n",
    "        \n",
    "            X_ = np.copy(tree.oob_X)\n",
    "            np.random.shuffle(X_[:,feature])\n",
    "            y_pred_j = tree.predict(X_) \n",
    "            acc_j = np.mean(y_true == y_pred_j)\n",
    "            err_oob_j = 1 - acc_j\n",
    "            \n",
    "            importance[feature] += err_oob_j - err_oob      \n",
    "            \n",
    "    importance /= rfc.n_estimators\n",
    "    return importance\n",
    "\n",
    "        \n",
    "def most_important_features(importance, names, k=20):\n",
    "    # Выводит названия k самых важных признаков\n",
    "    idicies = np.argsort(importance)[::-1][:k]\n",
    "    return np.array(names)[idicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на синтетическом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8gqYMp994q6B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Importance: [ 0.00135668  0.00174307  0.16618341  0.16306743  0.31957842 -0.00244449]\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dataset(size):\n",
    "    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n",
    "          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n",
    "    y = [i % 3 for i in range(size)]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = synthetic_dataset(1000)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n",
    "print(\"Importance:\", feature_importance(rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на датасете VK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HruobK-q4q6C"
   },
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    dataframe = pandas.read_csv(path, header=0)\n",
    "    dataset = dataframe.values.tolist()\n",
    "    random.shuffle(dataset)\n",
    "    y_age = [row[0] for row in dataset]\n",
    "    y_sex = [row[1] for row in dataset]\n",
    "    X = [row[2:] for row in dataset]\n",
    "    \n",
    "    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "K0QXWr3b4q6C"
   },
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0y8J97m4q6C"
   },
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MLJykJZH4q6C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7200504413619168\n",
      "Most important features:\n",
      "1. ovsyanochan\n",
      "2. styd.pozor\n",
      "3. 4ch\n",
      "4. rhymes\n",
      "5. mudakoff\n",
      "6. dayvinchik\n",
      "7. pravdashowtop\n",
      "8. rapnewrap\n",
      "9. iwantyou\n",
      "10. xfilm\n",
      "11. reflexia_our_feelings\n",
      "12. bot_maxim\n",
      "13. ne1party\n",
      "14. i_des\n",
      "15. ne.poverish\n",
      "16. pixel_stickers\n",
      "17. leprum\n",
      "18. memeboizz\n",
      "19. tumblr_vacuum\n",
      "20. soverwenstvo.decora\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "rfc.fit(X_train, y_age_train)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_age_test))\n",
    "print(\"Most important features:\")\n",
    "for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n",
    "    print(str(i+1) + \".\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgNpaAKH4q6D"
   },
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "X-zne5-R4q6D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8575031525851198\n",
      "Most important features:\n",
      "1. 40kg\n",
      "2. girlmeme\n",
      "3. zerofat\n",
      "4. mudakoff\n",
      "5. be.women\n",
      "6. modnailru\n",
      "7. igm\n",
      "8. bon\n",
      "9. femalemem\n",
      "10. sh.cook\n",
      "11. rapnewrap\n",
      "12. soverwenstvo.decora\n",
      "13. thesmolny\n",
      "14. reflexia_our_feelings\n",
      "15. 9o_6o_9o\n",
      "16. combovine\n",
      "17. i_d_t\n",
      "18. bot_maxim\n",
      "19. cook_good\n",
      "20. be.beauty\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "rfc.fit(X_train, y_sex_train)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_sex_test))\n",
    "print(\"Most important features:\")\n",
    "for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n",
    "    print(str(i+1) + \".\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "  Feature Id  Importances\n",
      "0          4    48.790074\n",
      "1          2    29.366018\n",
      "2          3    21.843610\n",
      "3          1     0.000298\n",
      "4          0     0.000000\n",
      "5          5     0.000000\n"
     ]
    }
   ],
   "source": [
    "from catboost import Pool\n",
    "\n",
    "X, y = synthetic_dataset(1000)\n",
    "cat_features = [0]\n",
    "\n",
    "model = CatBoostClassifier(iterations=10,\n",
    "                           learning_rate=1,\n",
    "                           depth=2,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "train_dataset = Pool(data=X,\n",
    "                     label=y,\n",
    "                     cat_features=cat_features)\n",
    "\n",
    "eval_dataset = Pool(data=X,\n",
    "                    label=y,\n",
    "                    cat_features=cat_features)\n",
    "\n",
    "model.fit(train_dataset, silent=True)\n",
    "y_pred = model.predict(eval_dataset).squeeze()\n",
    "\n",
    "print(\"Accuracy:\", np.mean(y_pred == y))\n",
    "print(model.get_feature_importance(data=None,\n",
    "                       prettified=True,\n",
    "                       thread_count=-1,\n",
    "                       verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n",
    "X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA5f_8eC4q6E"
   },
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.725094577553594\n",
      "    Feature Id  Importances\n",
      "0          135     3.062867\n",
      "1           38     2.850990\n",
      "2           75     2.351215\n",
      "3           23     2.245430\n",
      "4          101     2.200626\n",
      "..         ...          ...\n",
      "144        141     0.141622\n",
      "145         15     0.137504\n",
      "146         97     0.124924\n",
      "147        140     0.113374\n",
      "148         35     0.000000\n",
      "\n",
      "[149 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Pool(data=X_train, label=y_age_train)\n",
    "test_dataset = Pool(data=X_test, label=y_age_test)\n",
    "\n",
    "model = CatBoostClassifier(loss_function='MultiClass', silent=True)\n",
    "\n",
    "model.fit(train_dataset)\n",
    "y_pred = model.predict(test_dataset).squeeze()\n",
    "print(\"Accuracy:\", np.mean(y_pred == y_age_test))\n",
    "print(model.get_feature_importance(data=None,\n",
    "                       prettified=True,\n",
    "                       thread_count=-1,\n",
    "                       verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfYSptm74q6E"
   },
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n",
    "X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8852459016393442\n",
      "    Feature Id  Importances\n",
      "0           22     3.791130\n",
      "1           38     3.148981\n",
      "2           10     2.549417\n",
      "3           20     2.028881\n",
      "4          133     1.868518\n",
      "..         ...          ...\n",
      "144         49     0.149827\n",
      "145         56     0.139478\n",
      "146        107     0.123397\n",
      "147         70     0.117040\n",
      "148         85     0.110582\n",
      "\n",
      "[149 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Pool(data=X_train, label=y_sex_train)\n",
    "test_dataset = Pool(data=X_test, label=y_sex_test)\n",
    "\n",
    "model = CatBoostClassifier(loss_function='MultiClass', silent=True)\n",
    "\n",
    "model.fit(train_dataset)\n",
    "y_pred = model.predict(test_dataset).squeeze()\n",
    "print(\"Accuracy:\", np.mean(y_pred == y_sex_test))\n",
    "print(model.get_feature_importance(data=None,\n",
    "                       prettified=True,\n",
    "                       thread_count=-1,\n",
    "                       verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw09_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
